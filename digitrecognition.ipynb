{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.np_utils import to_categorical #convert numbers to one-hot-encoding\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "    \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('digit-recognizer/train.csv')\n",
    "test=pd.read_csv('digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img=test.iloc[0].as_matrix()\n",
    "img=img.reshape((28,28))\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x137577160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_orig=train['label']\n",
    "X_train_orig=train.drop(labels='label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_orig=Y_train_orig.values.reshape((Y_train_orig.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_orig,X_val,Y_train_orig,Y_val = train_test_split(X_train_orig,Y_train_orig,test_size=0.1,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "X_train_orig=X_train_orig.values.reshape(-1,28,28,1)\n",
    "test=test.values.reshape(-1,28,28,1)\n",
    "X_train=X_train_orig/225\n",
    "X_test=test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape\n",
    "Y_train=to_categorical(Y_train_orig,num_classes=10)\n",
    "\n",
    "# print(Y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val=to_categorical(Y_val,num_classes=10)\n",
    "X_val=X_val.values.reshape(-1,28,28,1)\n",
    "X_val=X_val/225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def digitRecognition(input_shape):\n",
    "    x_input=Input(input_shape)\n",
    "    x=ZeroPadding2D((3,3))(x_input)\n",
    "    x=Conv2D(32,(7,7),strides=(1,1),name='conv0')(x)\n",
    "    x=BatchNormalization(axis=3,name='bn0')(x)\n",
    "    x=Activation('relu')(x)\n",
    "    \n",
    "    x=MaxPooling2D((2,2),name='max_pool')(x)\n",
    "    x=Flatten()(x)\n",
    "    x=Dense(10,activation='softmax',name='fc')(x)\n",
    "    \n",
    "    model=Model(input=x_input,output=x,name='digitRecognition')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"digitRecognition\", inputs=Tensor(\"in..., outputs=Tensor(\"fc...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "digitR=digitRecognition((28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "digitR.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "37800/37800 [==============================] - 40s 1ms/step - loss: 0.1552 - acc: 0.9562\n",
      "Epoch 2/42\n",
      "37800/37800 [==============================] - 40s 1ms/step - loss: 0.0868 - acc: 0.9757\n",
      "Epoch 3/42\n",
      "37800/37800 [==============================] - 42s 1ms/step - loss: 0.0625 - acc: 0.9820\n",
      "Epoch 4/42\n",
      "37800/37800 [==============================] - 41s 1ms/step - loss: 0.0498 - acc: 0.9865\n",
      "Epoch 5/42\n",
      "37800/37800 [==============================] - 40s 1ms/step - loss: 0.0421 - acc: 0.9874\n",
      "Epoch 6/42\n",
      "37800/37800 [==============================] - 40s 1ms/step - loss: 0.0362 - acc: 0.9894\n",
      "Epoch 7/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0312 - acc: 0.9909\n",
      "Epoch 8/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 9/42\n",
      "37800/37800 [==============================] - 40s 1ms/step - loss: 0.0238 - acc: 0.9934\n",
      "Epoch 10/42\n",
      "37800/37800 [==============================] - 40s 1ms/step - loss: 0.0219 - acc: 0.9932\n",
      "Epoch 11/42\n",
      "37800/37800 [==============================] - 40s 1ms/step - loss: 0.0214 - acc: 0.9929\n",
      "Epoch 12/42\n",
      "37800/37800 [==============================] - 40s 1ms/step - loss: 0.0171 - acc: 0.9949\n",
      "Epoch 13/42\n",
      "37800/37800 [==============================] - 40s 1ms/step - loss: 0.0150 - acc: 0.9958\n",
      "Epoch 14/42\n",
      "37800/37800 [==============================] - 40s 1ms/step - loss: 0.0137 - acc: 0.9959\n",
      "Epoch 15/42\n",
      "37800/37800 [==============================] - 40s 1ms/step - loss: 0.0134 - acc: 0.9958\n",
      "Epoch 16/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0102 - acc: 0.9973\n",
      "Epoch 17/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0110 - acc: 0.9968\n",
      "Epoch 18/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 19/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0135 - acc: 0.9956\n",
      "Epoch 20/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0138 - acc: 0.9958\n",
      "Epoch 21/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0098 - acc: 0.9968\n",
      "Epoch 22/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0073 - acc: 0.9976\n",
      "Epoch 23/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0051 - acc: 0.9988\n",
      "Epoch 24/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0035 - acc: 0.9994\n",
      "Epoch 25/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0017 - acc: 0.9999\n",
      "Epoch 26/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 27/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 28/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 29/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 30/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 9.2597e-04 - acc: 1.0000\n",
      "Epoch 31/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 8.9978e-04 - acc: 1.0000\n",
      "Epoch 32/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 9.1274e-04 - acc: 1.0000\n",
      "Epoch 33/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 8.4971e-04 - acc: 1.0000\n",
      "Epoch 34/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0205 - acc: 0.9943\n",
      "Epoch 35/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0593 - acc: 0.9842\n",
      "Epoch 36/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0113 - acc: 0.9963\n",
      "Epoch 37/42\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0060 - acc: 0.9983\n",
      "Epoch 38/42\n",
      "37800/37800 [==============================] - 44s 1ms/step - loss: 0.0030 - acc: 0.9992\n",
      "Epoch 39/42\n",
      "37800/37800 [==============================] - 43s 1ms/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 40/42\n",
      "37800/37800 [==============================] - 45s 1ms/step - loss: 9.6028e-04 - acc: 1.0000\n",
      "Epoch 41/42\n",
      "37800/37800 [==============================] - 42s 1ms/step - loss: 7.7770e-04 - acc: 1.0000\n",
      "Epoch 42/42\n",
      "37800/37800 [==============================] - 43s 1ms/step - loss: 7.1475e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10d1f2ef0>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitR.fit(x=X_train,y=Y_train,epochs=42,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 2s 485us/step\n",
      "\n",
      "loss=0.06659436791860875\n",
      "accuracy=0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "preds=digitR.evaluate(x=X_val,y=Y_val)\n",
    "print()\n",
    "print(\"loss=\"+str(preds[0]))\n",
    "print(\"accuracy=\"+str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=digitR.predict(X_test)\n",
    "Y_test=np.argmax(Y_test,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ans=pd.Series(Y_test,name='Label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ImageId  Label\n",
      "0        1      2\n",
      "1        2      0\n",
      "2        3      9\n",
      "3        4      0\n",
      "4        5      3\n",
      "5        6      7\n",
      "6        7      0\n",
      "7        8      3\n",
      "8        9      0\n",
      "9       10      3\n"
     ]
    }
   ],
   "source": [
    "ans=pd.concat([pd.Series(range(1,Y_ans.shape[0]+1),name='ImageId'),Y_ans],axis=1)\n",
    "print(ans[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission=ans.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
